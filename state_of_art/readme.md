# State of Art of real-time Anomaly Detection

| Dimension | Axis | Options |
|-----------|------|---------|
| **Granularity (Who is the model for?)** | Global ‚Üí Segment ‚Üí Personalized ‚Üí Per-Customer |
| **Lifecycle (How long is the model valid?)** | Static ‚Üí Periodic ‚Üí Online ‚Üí Disposable |

## üåê Dimension 1: *Granularity of Modeling*

The first dimension is **granularity** 
- ranging from global models to individual (per-customer) models.
- In between these two extremes lies the **segment-based approach**,
  - where customers are grouped into cohorts or clusters with similar behavior/ metadata (plan type, geography, device type, usage intensity, etc.).
  - This creates a semi-global or multi-customer model that balances scalability and personalization.

```
                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                     ‚îÇ       Global Model            ‚îÇ
                     ‚îÇ  Trained on ALL customers     ‚îÇ
                     ‚îÇ  {A1,A2,A3,B1,B2,B3,C1,C2,C3} ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚Üì
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ         Segment-Based / Cohort Models (Semi-Global)          ‚îÇ
       ‚îÇ                                                               ‚îÇ
       ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
       ‚îÇ   ‚îÇ  Model A     ‚îÇ   ‚îÇ  Model B     ‚îÇ   ‚îÇ  Model C     ‚îÇ      ‚îÇ
       ‚îÇ   ‚îÇ {A1,A2,A3}   ‚îÇ   ‚îÇ {B1,B2,B3}   ‚îÇ   ‚îÇ {C1,C2,C3}   ‚îÇ      ‚îÇ
       ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                   ‚Üì
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ                 Individual / Per-Customer Models              ‚îÇ
       ‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
       ‚îÇ   ‚îÇ A1  ‚îÇ ‚îÇ A2  ‚îÇ ‚îÇ A3  ‚îÇ ‚îÇ B1  ‚îÇ ‚îÇ B2  ‚îÇ ‚îÇ B3  ‚îÇ ‚îÇ C1  ‚îÇ ... ‚îÇ
       ‚îÇ   ‚îÇM_A1 ‚îÇ ‚îÇM_A2 ‚îÇ ‚îÇM_A3 ‚îÇ ‚îÇM_B1 ‚îÇ ‚îÇM_B2 ‚îÇ ‚îÇM_B3 ‚îÇ ‚îÇM_C1 ‚îÇ     ‚îÇ
       ‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò



Global ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Segment-Based ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Individual
(model for all)      ‚îÇ       (cluster/cohort models)            ‚îÇ    (per-customer model)
                     ‚îÇ                                          ‚îÇ
         Semi-Global / Multi-Customer                    Highly Personalized

```


### 1. Global-but-personalized models (multi-entity TS, entity embeddings)

This is basically the **DeepAR / TFT style** approach:

- Train **one big sequence model** (RNN/Transformer/Temporal CNN) on *all* customers.
- Feed **customer ID (or customer embedding + metadata)** into the model as extra features.
- The model learns:
  - **Global regularities** (diurnal / weekly patterns, holidays, network-wide events).
  - **Per-customer idiosyncrasies** via embeddings.

**Pros**
- You automatically get personalization without storing a separate model per customer.
- Works well when you have tons of related time series.

**Cons**
- Harder to interpret than simple per-customer rules/stat models.
- Needs careful handling of concept drift and new customers.
- Deployment complexity (GPU/serving, latency).



### 2. Two-Stage Detection: cheap global + expensive local

To cope with scale, use **two stages**:

1. **Stage 1: Very cheap filter** (global thresholds, global model, or simple per-customer stats).
   - Goal: filter 99% of ‚Äúobviously normal‚Äù events.

2. **Stage 2: Heavy model only for suspicious candidates**
   - Could be:
     - Per-customer on-the-fly model,
     - A global-but-personalized deep model,
     - A full embedding + nearest neighbor search.

more general, this could be Hierarchical / multi-level detectors (customer ‚Üí cell ‚Üí region ‚Üí global)


**Pros**
- Much cheaper than running heavy models everywhere.

**Cons**
- Risk of missing anomalies if Stage 1 is too aggressive.
- Pipeline complexity (two types of models, two latencies).



### 3. Meta-learning ‚Äúfast per-customer adaptation‚Äù

Use **meta-learning**:

1. Train a meta-model across all customers so that:
2. Given a small amount of recent data from a new customer,
3. You can quickly adapt to this customer with 1‚Äì2 gradient steps (MAML-style) or fine-tuning of a small head.

Workflow:

1. Offline: meta-train across many customers‚Äô histories.
2. Online: when you get a new/changed customer:
   - Start from the meta-initialization,
   - Do a tiny bit of adaptation on their most recent history,
   - Use the adapted model for anomaly scoring.

this is similar to llm few-shot methodology. you train a large model use customer information, and then fine-tune adapt to personalized information.

**Pros**
- Gets close to ‚Äúper-customer custom models‚Äù without full retraining each time.
- Handles dynamic customers better than a static global model.

**Cons**
- Research-y; serving & training infra is not trivial.
- Needs enough historical customers to meta-train.


---

## ‚è≥ Dimension 2: *Lifecycle of Training & Usage*
This dimension concerns **how long a model remains valid before retraining**‚Äîwhich is especially important in real-time detection where concept drift is high.

| Lifecycle Strategy | Description | Suitable For |
|--------------------|-------------|--------------|
| **Static (Train Once, Use Long-Term)** | Train once, reuse model for weeks/months. | Stable domains (like house pricing) |
| **Periodic Retraining (Batch)** | Retrain daily/weekly using new data. | Medium-drift environments |
| **Incremental / Online Learning** | Model updates continuously as new data arrives. | Streaming, evolving data |
| **Disposable (Train-Use-Discard)** | Model trained on historical window, used once to detect anomalies, then discarded. | Highly dynamic environments (novelty, drift) |


In real-time anomaly detection, data is **highly time-sensitive**, and historical patterns may quickly become irrelevant. Therefore:

> A model trained using Day 1‚Äì14 may **not** be reliable to detect anomalies in Day 20.  
> Because user behavior, network conditions, or external dynamics **change too rapidly**.

Thus, **Disposable or Online models** are often preferred for novelty detection.


---


## 2. How tech companies handle massive real-time anomaly detection

Here are some concrete systems you can study and steal ideas from:

- **LinkedIn ‚Äì ThirdEye**
  - ThirdEye is LinkedIn‚Äôs business-wide monitoring platform for detecting anomalies in KPI time series across many products and dimensions (country, segment, experiment, etc.).  
  - It supports multiple algorithms, automatic root cause analysis over high-cardinality dimensions, and smart alerting tuned to business sensitivity. :contentReference[oaicite:9]{index=9}  

- **Uber ‚Äì M3 + uVitals + alerting ecosystem**
  - **M3**: Uber‚Äôs open-source, large-scale metrics platform used as remote storage for Prometheus; designed explicitly for multi-tenant, high-cardinality metrics (thousands of services, billions of time series). :contentReference[oaicite:10]{index=10}  
  - **uVitals**: newer anomaly detection and alerting system specialized for multi-dimensional time-series data, working in an unsupervised fashion for service health. :contentReference[oaicite:11]{index=11}  
  - **Observability at scale**: Uber describes how they built metrics & alerting pipelines (uMonitor, Neris) on top of this stack. :contentReference[oaicite:12]{index=12}  

- **Twitter / X ‚Äì AnomalyDetection & S-H-ESD**
  - Twitter‚Äôs engineering blog details how they built practical and robust anomaly detection in time series using Seasonal Hybrid ESD, including treatment of seasonal patterns and long histories. :contentReference[oaicite:13]{index=13}  
  - Many open-source reimplementations exist; these are widely used as baselines for metric anomaly detection.

- **Grafana Labs ‚Äì Prometheus + Mimir anomaly detection**
  - Grafana Cloud runs multi-tenant metrics storage (Mimir) and has shared how they implement anomaly detection rules over Prometheus-style metrics at scale. This is very close to your ‚Äúhundreds of thousands customers‚Äù case if you treat each customer √ó metric pair as a series. :contentReference[oaicite:14]{index=14}  

- **Amazon ‚Äì DeepAR / Amazon Forecast**
  - DeepAR is used internally (and via Amazon Forecast) for large-scale forecasting across many SKUs / entities; anomaly detection is often implemented as ‚Äúforecast + residual thresholding‚Äù on top of these models. :contentReference[oaicite:15]{index=15}  

- **Commercial / infra products**
  - **StarTree ThirdEye**: productized anomaly detection and root-cause analysis for OLAP metrics (built on Apache Pinot), used by companies like Confluent and Walmart. :contentReference[oaicite:16]{index=16}  
  - **Enterprise TS DBs & observability tools** (VictoriaMetrics Enterprise, Cortex, etc.) often ship anomaly detection and multi-tenant statistics specifically for large numbers of metric streams. :contentReference[oaicite:17]{index=17}  

---


## 3. Resources (papers, docs, libraries) tied to the above ideas

Here are some concrete things to read / look at, mapped loosely to the options:

- **Global-but-personalized time-series models (Option 5, 12)**
  - DeepAR paper: probabilistic forecasting with a single RNN trained over many related time series; the ideas map directly to global anomaly thresholds on forecast residuals. :contentReference[oaicite:0]{index=0}  
  - Amazon Forecast DeepAR+ docs show how this style of model is productized for multi-entity forecasting. :contentReference[oaicite:1]{index=1}  

- **Robust seasonal decomposition + anomaly detection (Options 1/4/7/9)**
  - Twitter‚Äôs Seasonal Hybrid ESD (S-H-ESD) for time-series anomalies; used in their internal AnomalyDetection tool and widely replicated. :contentReference[oaicite:2]{index=2}  
  - ‚ÄúEnhanced Seasonal-Hybrid ESD (SH-ESD+)‚Äù extends this idea for more robust detection, especially for long seasonal series. :contentReference[oaicite:3]{index=3}  

- **Multi-dimensional / multi-tenant anomaly platforms (Options 4/8/10/11)**
  - LinkedIn‚Äôs ThirdEye: end-to-end anomaly detection, smart alerts, and root-cause for business metrics; their blogs discuss multi-dimensional metrics, grouping, and high cardinality. :contentReference[oaicite:4]{index=4}  
  - StarTree ThirdEye (commercialization) documents how companies like Walmart and Confluent use it for business monitoring at scale. :contentReference[oaicite:5]{index=5}  

- **Streaming / metrics-focused anomaly detection (Options 7/8/10)**
  - Grafana‚Äôs ‚ÄúHow to use Prometheus to efficiently detect anomalies at scale‚Äù describes large-scale, explainable anomaly detection on multi-tenant metrics (using Mimir). :contentReference[oaicite:6]{index=6}  
  - Uber‚Äôs anomaly detection platform blog (‚ÄúImplementing Model-Agnosticism in Uber‚Äôs Real-Time Anomaly Detection‚Äù) describes a model-agnostic pipeline that can host multiple algorithms behind one alerting system. :contentReference[oaicite:7]{index=7}  

- **Federated / multi-tenant research (Option 11)**
  - Recent work on ‚ÄúFederated Anomaly Detection for Multi-Tenant Cloud Environments‚Äù proposes federated detection for dynamic, high-cardinality tenants. :contentReference[oaicite:8]{index=8}  

These are good starting points to see how your conceptual options show up in real code / systems.

---
